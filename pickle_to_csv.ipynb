{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mldb_2021-07-16.pickle\", 'rb') as f:\n",
    "    evals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore checkpoints for now\n",
    "df = df[df.epoch == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add accurcy metric and ci\n",
    "df['accuracy'] = df.stats.apply(lambda x: x['num_correct_and_size'][0] / x['num_correct_and_size'][1])\n",
    "\n",
    "num_correct_vals = df.stats.apply(lambda x: x['num_correct_and_size'][0]).values\n",
    "size_vals = df.stats.apply(lambda x: x['num_correct_and_size'][1]).values\n",
    "cis = sms.proportion_confint(num_correct_vals, size_vals, alpha=0.05, method='beta')\n",
    "df['accuracy_ci'] = list(zip(*cis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add macro_f1 metric and ci\n",
    "def confint(acc, n, alpha=0.05, method=\"beta\"):\n",
    "    return sms.proportion_confint(acc * n, n, alpha=alpha, method=method)\n",
    "\n",
    "def worst_region_acc_ci(ev):\n",
    "        \"\"\"Compute Clopper-Pearson CI for the worst-region subgroup.\"\"\"\n",
    "        # Find the number of points in the worst-region\n",
    "        if 'wilds_metrics' not in ev or 'acc_worst_region' not in ev['wilds_metrics']:\n",
    "            return (0., 0.)\n",
    "        regions = [\"Asia\", \"Europe\", \"Africa\", \"Americas\", \"Oceania\", \"Other\"]\n",
    "        worst_acc = ev['wilds_metrics'][\"acc_worst_region\"]\n",
    "        worst_region_size = None\n",
    "        for region in regions:\n",
    "            if np.isclose(worst_acc, ev['wilds_metrics'][f\"acc_region:{region}\"]):\n",
    "                worst_region_size = ev['wilds_metrics'][f\"count_region:{region}\"]\n",
    "                break\n",
    "        assert worst_region_size is not None\n",
    "        # Note: This confidence interval isn't exactly correct because we took\n",
    "        # a max over the worst-region first...\n",
    "        num_correct = int(worst_region_size * worst_acc)\n",
    "        return sms.proportion_confint(\n",
    "            num_correct, worst_region_size, alpha=0.05, method=\"beta\"\n",
    "        )\n",
    "\n",
    "df['macro_f1'] = df.stats.apply(lambda x: x.get('wilds_metrics', {}).get('F1-macro_all', None))\n",
    "df['macro_f1_ci'] = df.stats.apply(lambda x: x.get('iwc_f1_approx_ci_95', (0., 0.))) # TEMPORARY\n",
    "\n",
    "df['worst_region_accuracy'] = df.stats.apply(lambda x: x.get('wilds_metrics', {}).get('acc_worst_region', None))\n",
    "df['worst_region_accuracy_ci'] = df.stats.apply(worst_region_acc_ci)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairs of id-train, id-test\n",
    "ID_PAIRS = [\n",
    "    (\"cifar10-train\", \"cifar10-test\"),\n",
    "    (\"cifar10-train\", \"cifar10-STL10classes\"),\n",
    "    (\"FMoW-train\", \"FMoW-id_test\"),\n",
    "    (\"FMoW-train\", \"FMoW-id_val\"),\n",
    "    (\"Camelyon17-train\", \"Camelyon17-id_val\"),\n",
    "    (\"Camelyon17-train\", \"Camelyon17-id_test\"),\n",
    "    (\"IWildCamOfficialV2-train\", \"IWildCamOfficialV2-id_val\"),\n",
    "    (\"IWildCamOfficialV2-train\", \"IWildCamOfficialV2-id_test\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(_df, train, test):\n",
    "    test_eval = _df[_df.test_set == test]\n",
    "    if len(test_eval) == 0:\n",
    "        return pd.DataFrame()\n",
    "    test_eval = test_eval.iloc[0]\n",
    "    shift_evals = _df[~_df.test_set.isin([train, test])]\n",
    "    newdf = shift_evals[[\"model_family\", \"model_id\", \"epoch\", \"rule_params\"]]\n",
    "    newdf = newdf.rename(columns={\"rule_params\": \"hyperparameters\"})\n",
    "    newdf[\"train_set\"] = train\n",
    "    newdf[\"test_set\"] = test\n",
    "    newdf[\"shift_set\"] = shift_evals[\"test_set\"]\n",
    "    for metric in [\"accuracy\", \"macro_f1\", \"worst_region_accuracy\"]:\n",
    "        newdf[f\"test_{metric}\"] = test_eval[metric]\n",
    "        newdf[f\"test_{metric}_ci\"] = [test_eval[f\"{metric}_ci\"] for _ in range(len(newdf))]\n",
    "        newdf[f\"shift_{metric}\"] = shift_evals[metric]\n",
    "        newdf[f\"shift_{metric}_ci\"] = shift_evals[f\"{metric}_ci\"]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "for train, test in ID_PAIRS:\n",
    "    df_train = df[df.train_set == train]\n",
    "    shift_sets = set(df_train.test_set) - set([train, test])\n",
    "    new_df.extend([reformat(modeldf, train, test) for _, modeldf in df_train.groupby(\"model_id\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_model_family(model_family):\n",
    "    if \"RandFeatures\" in model_family:\n",
    "        return \"RandomFeatures\"\n",
    "    elif \"K_nearest_neighbors\" in model_family:\n",
    "        return \"KNN\"\n",
    "    return model_family\n",
    "\n",
    "new_df[\"model_family\"] = new_df.model_family.apply(rename_model_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_test_set(ts):\n",
    "    if ts == \"cifar10-STL10classes\":\n",
    "        return \"cifar10-test-STL10classes\"\n",
    "    return ts\n",
    "new_df[\"test_set\"] = new_df.test_set.apply(rename_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_family</th>\n",
       "      <th>model_id</th>\n",
       "      <th>epoch</th>\n",
       "      <th>hyperparameters</th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "      <th>shift_set</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_accuracy_ci</th>\n",
       "      <th>shift_accuracy</th>\n",
       "      <th>shift_accuracy_ci</th>\n",
       "      <th>test_macro_f1</th>\n",
       "      <th>test_macro_f1_ci</th>\n",
       "      <th>shift_macro_f1</th>\n",
       "      <th>shift_macro_f1_ci</th>\n",
       "      <th>test_worst_region_accuracy</th>\n",
       "      <th>test_worst_region_accuracy_ci</th>\n",
       "      <th>shift_worst_region_accuracy</th>\n",
       "      <th>shift_worst_region_accuracy_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>RandomFeatures</td>\n",
       "      <td>00082624-3fbe-46de-8c7c-b45f38a88e87</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'num_filters': 64, 'patch_size': 6, 'pool_siz...</td>\n",
       "      <td>cifar10-train</td>\n",
       "      <td>cifar10-test</td>\n",
       "      <td>cifar10c_impulse_noise_2</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>(0.6456894668728717, 0.6644201270832805)</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>(0.47555981191619107, 0.4952486953322158)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>RandomFeatures</td>\n",
       "      <td>00082624-3fbe-46de-8c7c-b45f38a88e87</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'num_filters': 64, 'patch_size': 6, 'pool_siz...</td>\n",
       "      <td>cifar10-train</td>\n",
       "      <td>cifar10-test</td>\n",
       "      <td>cifar10c_fog_2</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>(0.6456894668728717, 0.6644201270832805)</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>(0.6238676403350546, 0.6428546097260688)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>RandomFeatures</td>\n",
       "      <td>00082624-3fbe-46de-8c7c-b45f38a88e87</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'num_filters': 64, 'patch_size': 6, 'pool_siz...</td>\n",
       "      <td>cifar10-train</td>\n",
       "      <td>cifar10-test</td>\n",
       "      <td>cifar10c_frost_5</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>(0.6456894668728717, 0.6644201270832805)</td>\n",
       "      <td>0.5104</td>\n",
       "      <td>(0.5005504702099839, 0.5202434698407776)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>RandomFeatures</td>\n",
       "      <td>00082624-3fbe-46de-8c7c-b45f38a88e87</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'num_filters': 64, 'patch_size': 6, 'pool_siz...</td>\n",
       "      <td>cifar10-train</td>\n",
       "      <td>cifar10-test</td>\n",
       "      <td>cifar10c_snow_all</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>(0.6456894668728717, 0.6644201270832805)</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>(0.5518320019958354, 0.560561471986289)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>RandomFeatures</td>\n",
       "      <td>00082624-3fbe-46de-8c7c-b45f38a88e87</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'num_filters': 64, 'patch_size': 6, 'pool_siz...</td>\n",
       "      <td>cifar10-train</td>\n",
       "      <td>cifar10-test</td>\n",
       "      <td>cifar10c_saturate_2</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>(0.6456894668728717, 0.6644201270832805)</td>\n",
       "      <td>0.5694</td>\n",
       "      <td>(0.5596259942066042, 0.5791335647014177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_family                              model_id  epoch  \\\n",
       "14976  RandomFeatures  00082624-3fbe-46de-8c7c-b45f38a88e87     -1   \n",
       "14977  RandomFeatures  00082624-3fbe-46de-8c7c-b45f38a88e87     -1   \n",
       "14978  RandomFeatures  00082624-3fbe-46de-8c7c-b45f38a88e87     -1   \n",
       "14979  RandomFeatures  00082624-3fbe-46de-8c7c-b45f38a88e87     -1   \n",
       "14980  RandomFeatures  00082624-3fbe-46de-8c7c-b45f38a88e87     -1   \n",
       "\n",
       "                                         hyperparameters      train_set  \\\n",
       "14976  {'num_filters': 64, 'patch_size': 6, 'pool_siz...  cifar10-train   \n",
       "14977  {'num_filters': 64, 'patch_size': 6, 'pool_siz...  cifar10-train   \n",
       "14978  {'num_filters': 64, 'patch_size': 6, 'pool_siz...  cifar10-train   \n",
       "14979  {'num_filters': 64, 'patch_size': 6, 'pool_siz...  cifar10-train   \n",
       "14980  {'num_filters': 64, 'patch_size': 6, 'pool_siz...  cifar10-train   \n",
       "\n",
       "           test_set                 shift_set  test_accuracy  \\\n",
       "14976  cifar10-test  cifar10c_impulse_noise_2         0.6551   \n",
       "14977  cifar10-test            cifar10c_fog_2         0.6551   \n",
       "14978  cifar10-test          cifar10c_frost_5         0.6551   \n",
       "14979  cifar10-test         cifar10c_snow_all         0.6551   \n",
       "14980  cifar10-test       cifar10c_saturate_2         0.6551   \n",
       "\n",
       "                               test_accuracy_ci  shift_accuracy  \\\n",
       "14976  (0.6456894668728717, 0.6644201270832805)          0.4854   \n",
       "14977  (0.6456894668728717, 0.6644201270832805)          0.6334   \n",
       "14978  (0.6456894668728717, 0.6644201270832805)          0.5104   \n",
       "14979  (0.6456894668728717, 0.6644201270832805)          0.5562   \n",
       "14980  (0.6456894668728717, 0.6644201270832805)          0.5694   \n",
       "\n",
       "                               shift_accuracy_ci  test_macro_f1  \\\n",
       "14976  (0.47555981191619107, 0.4952486953322158)            NaN   \n",
       "14977   (0.6238676403350546, 0.6428546097260688)            NaN   \n",
       "14978   (0.5005504702099839, 0.5202434698407776)            NaN   \n",
       "14979    (0.5518320019958354, 0.560561471986289)            NaN   \n",
       "14980   (0.5596259942066042, 0.5791335647014177)            NaN   \n",
       "\n",
       "      test_macro_f1_ci  shift_macro_f1 shift_macro_f1_ci  \\\n",
       "14976       (0.0, 0.0)             NaN        (0.0, 0.0)   \n",
       "14977       (0.0, 0.0)             NaN        (0.0, 0.0)   \n",
       "14978       (0.0, 0.0)             NaN        (0.0, 0.0)   \n",
       "14979       (0.0, 0.0)             NaN        (0.0, 0.0)   \n",
       "14980       (0.0, 0.0)             NaN        (0.0, 0.0)   \n",
       "\n",
       "       test_worst_region_accuracy test_worst_region_accuracy_ci  \\\n",
       "14976                         NaN                    (0.0, 0.0)   \n",
       "14977                         NaN                    (0.0, 0.0)   \n",
       "14978                         NaN                    (0.0, 0.0)   \n",
       "14979                         NaN                    (0.0, 0.0)   \n",
       "14980                         NaN                    (0.0, 0.0)   \n",
       "\n",
       "       shift_worst_region_accuracy shift_worst_region_accuracy_ci  \n",
       "14976                          NaN                     (0.0, 0.0)  \n",
       "14977                          NaN                     (0.0, 0.0)  \n",
       "14978                          NaN                     (0.0, 0.0)  \n",
       "14979                          NaN                     (0.0, 0.0)  \n",
       "14980                          NaN                     (0.0, 0.0)  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add YCB objects results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ycb_50ktrain_evals.json\") as handle:\n",
    "    ycb50 = json.load(handle)\n",
    "    for e in ycb50:\n",
    "        del e[\"hparams\"][\"train:outdir\"]\n",
    "        e[\"test_ci\"] = tuple(e[\"test_ci\"])\n",
    "        e[\"shift_ci\"] = tuple(e[\"shift_ci\"])\n",
    "\n",
    "with open(\"ycb_100ktrain_evals.json\") as handle:\n",
    "    ycb100 = json.load(handle)\n",
    "    for e in ycb100:\n",
    "        del e[\"hparams\"][\"train:outdir\"]\n",
    "        e[\"test_ci\"] = tuple(e[\"test_ci\"])\n",
    "        e[\"shift_ci\"] = tuple(e[\"shift_ci\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_ycb(ycb_data, trainset):\n",
    "    ycb_df = pd.DataFrame(ycb_data)\n",
    "    ycb_df = ycb_df.rename(columns={\n",
    "        \"model\": \"model_family\", \n",
    "        \"hparams\": \"hyperparameters\", \n",
    "        \"test_score\": \"test_accuracy\", \n",
    "        \"shift_score\": \"shift_accuracy\",\n",
    "        \"test_ci\": \"test_accuracy_ci\",\n",
    "        \"shift_ci\": \"shift_accuracy_ci\"\n",
    "    })\n",
    "    ycb_df[\"train_set\"] = trainset\n",
    "    ycb_df[\"test_set\"] = \"YCB ID Test\"\n",
    "    ycb_df[\"shift_set\"] = \"YCB OOD Test\"\n",
    "    \n",
    "    null_ci = [(0., 0.) for _ in range(len(ycb_df))]\n",
    "    \n",
    "    ycb_df[\"test_macro_f1_ci\"] = null_ci\n",
    "    ycb_df[\"shift_macro_f1_ci\"] = null_ci\n",
    "    ycb_df[\"test_worst_region_accuracy_ci\"] = null_ci\n",
    "    ycb_df[\"shift_worst_region_accuracy_ci\"] = null_ci\n",
    "    return ycb_df\n",
    "\n",
    "ycb50 = reformat_ycb(ycb50, \"YCB Train 50k examples\")\n",
    "ycb100 = reformat_ycb(ycb100, \"YCB Train 100k examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([new_df, ycb50, ycb100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results.csv\",\n",
    "    converters={\n",
    "        \"hyperparameters\": ast.literal_eval,\n",
    "        \"test_accuracy_ci\": ast.literal_eval,\n",
    "        \"shift_accuracy_ci\": ast.literal_eval,\n",
    "        \"test_macro_f1_ci\": ast.literal_eval,\n",
    "        \"shift_macro_f1_ci\": ast.literal_eval,\n",
    "        \"test_worst_region_accuracy_ci\": ast.literal_eval,\n",
    "        \"shift_worst_region_accuracy_ci\": ast.literal_eval,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
