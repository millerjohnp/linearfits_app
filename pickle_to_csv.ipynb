{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "import statsmodels.stats.api as sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mldb_2021-07-16.pickle\", 'rb') as f:\n",
    "    evals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore checkpoints for now\n",
    "df = df[df.epoch == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add accurcy metric and ci\n",
    "df['accuracy'] = df.stats.apply(lambda x: x['num_correct_and_size'][0] / x['num_correct_and_size'][1])\n",
    "\n",
    "num_correct_vals = df.stats.apply(lambda x: x['num_correct_and_size'][0]).values\n",
    "size_vals = df.stats.apply(lambda x: x['num_correct_and_size'][1]).values\n",
    "cis = sms.proportion_confint(num_correct_vals, size_vals, alpha=0.05, method='beta')\n",
    "df['accuracy_ci'] = list(zip(*cis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add macro_f1 metric and ci\n",
    "def confint(acc, n, alpha=0.05, method=\"beta\"):\n",
    "    return sms.proportion_confint(acc * n, n, alpha=alpha, method=method)\n",
    "\n",
    "def worst_region_acc_ci(ev):\n",
    "        \"\"\"Compute Clopper-Pearson CI for the worst-region subgroup.\"\"\"\n",
    "        # Find the number of points in the worst-region\n",
    "        if 'wilds_metrics' not in ev or 'acc_worst_region' not in ev['wilds_metrics']:\n",
    "            return (0., 0.)\n",
    "        regions = [\"Asia\", \"Europe\", \"Africa\", \"Americas\", \"Oceania\", \"Other\"]\n",
    "        worst_acc = ev['wilds_metrics'][\"acc_worst_region\"]\n",
    "        worst_region_size = None\n",
    "        for region in regions:\n",
    "            if np.isclose(worst_acc, ev['wilds_metrics'][f\"acc_region:{region}\"]):\n",
    "                worst_region_size = ev['wilds_metrics'][f\"count_region:{region}\"]\n",
    "                break\n",
    "        assert worst_region_size is not None\n",
    "        # Note: This confidence interval isn't exactly correct because we took\n",
    "        # a max over the worst-region first...\n",
    "        num_correct = int(worst_region_size * worst_acc)\n",
    "        return sms.proportion_confint(\n",
    "            num_correct, worst_region_size, alpha=0.05, method=\"beta\"\n",
    "        )\n",
    "\n",
    "df['macro_f1'] = df.stats.apply(lambda x: x.get('wilds_metrics', {}).get('F1-macro_all', None))\n",
    "df['macro_f1_ci'] = df.stats.apply(lambda x: x.get('iwc_f1_approx_ci_95', (0., 0.))) # TEMPORARY\n",
    "\n",
    "df['worst_region_accuracy'] = df.stats.apply(lambda x: x.get('wilds_metrics', {}).get('acc_worst_region', None))\n",
    "df['worst_region_accuracy_ci'] = df.stats.apply(worst_region_acc_ci)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairs of id-train, id-test\n",
    "ID_PAIRS = [\n",
    "    (\"cifar10-train\", \"cifar10-test\"),\n",
    "    (\"cifar10-train\", \"cifar10-STL10classes\"),\n",
    "    (\"FMoW-train\", \"FMoW-id_test\"),\n",
    "    (\"FMoW-train\", \"FMoW-id_val\"),\n",
    "    (\"Camelyon17-train\", \"Camelyon17-id_val\"),\n",
    "    (\"Camelyon17-train\", \"Camelyon17-id_test\"),\n",
    "    (\"IWildCamOfficialV2-train\", \"IWildCamOfficialV2-id_val\"),\n",
    "    (\"IWildCamOfficialV2-train\", \"IWildCamOfficialV2-id_test\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(_df, train, test):\n",
    "    test_eval = _df[_df.test_set == test]\n",
    "    if len(test_eval) == 0:\n",
    "        return pd.DataFrame()\n",
    "    test_eval = test_eval.iloc[0]\n",
    "    shift_evals = _df[~_df.test_set.isin([train, test])]\n",
    "    newdf = shift_evals[[\"model_family\", \"model_id\", \"epoch\", \"rule_params\"]]\n",
    "    newdf = newdf.rename(columns={\"rule_params\": \"hyperparameters\"})\n",
    "    newdf[\"train_set\"] = train\n",
    "    newdf[\"test_set\"] = test\n",
    "    newdf[\"shift_set\"] = shift_evals[\"test_set\"]\n",
    "    for metric in [\"accuracy\", \"macro_f1\", \"worst_region_accuracy\"]:\n",
    "        newdf[f\"test_{metric}\"] = test_eval[metric]\n",
    "        newdf[f\"test_{metric}_ci\"] = [test_eval[f\"{metric}_ci\"] for _ in range(len(newdf))]\n",
    "        newdf[f\"shift_{metric}\"] = shift_evals[metric]\n",
    "        newdf[f\"shift_{metric}_ci\"] = shift_evals[f\"{metric}_ci\"]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = []\n",
    "for train, test in ID_PAIRS:\n",
    "    df_train = df[df.train_set == train]\n",
    "    shift_sets = set(df_train.test_set) - set([train, test])\n",
    "    new_df.extend([reformat(modeldf, train, test) for _, modeldf in df_train.groupby(\"model_id\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_model_family(model_family):\n",
    "    if \"RandFeatures\" in model_family:\n",
    "        return \"RandomFeatures\"\n",
    "    elif \"K_nearest_neighbors\" in model_family:\n",
    "        return \"KNN\"\n",
    "    return model_family\n",
    "\n",
    "new_df[\"model_family\"] = new_df.model_family.apply(rename_model_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_test_set(ts):\n",
    "    if ts == \"cifar10-STL10classes\":\n",
    "        return \"cifar10-test-STL10classes\"\n",
    "    return ts\n",
    "new_df[\"test_set\"] = new_df.test_set.apply(rename_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
